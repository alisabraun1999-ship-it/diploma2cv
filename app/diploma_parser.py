# app/diploma_parser.py
import PyPDF2
import pdfplumber
import re
import os
import json
import tempfile
import subprocess
from typing import Dict, List, Any
from pathlib import Path

class OCRProcessor:
    @staticmethod
    def is_tesseract_available():
        try:
            result = subprocess.run(['tesseract', '--version'], capture_output=True, text=True, timeout=10)
            return result.returncode == 0
        except:
            return False

    @staticmethod
    def extract_text_with_ocr(file_path: str) -> str:
        text = ""
        try:
            print("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º OCR –æ–±—Ä–∞–±–æ—Ç–∫—É...")
            if not os.path.exists(file_path):
                print(f"‚ùå –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_path}")
                return ""

            from pdf2image import convert_from_path
            from PIL import Image, ImageEnhance

            print("üìä –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
            try:
                images = convert_from_path(file_path, dpi=400, thread_count=2)
                print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(images)} —Å—Ç—Ä–∞–Ω–∏—Ü")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF: {e}")
                return ""

            for i, image in enumerate(images):
                try:
                    print(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {i+1}/{len(images)}...")
                    temp_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)
                    image_path = temp_file.name
                    temp_file.close()

                    img = image.convert('L')
                    enhancer = ImageEnhance.Contrast(img)
                    img = enhancer.enhance(2.5)
                    enhancer = ImageEnhance.Sharpness(img)
                    img = enhancer.enhance(2.0)
                    img.save(image_path, 'PNG', quality=100)

                    print("   –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ç–µ–∫—Å—Ç...")
                    result = subprocess.run([
                        'tesseract', image_path, 'stdout', '-l', 'rus+eng', '--psm', '6'
                    ], capture_output=True, timeout=120)

                    if result.returncode == 0:
                        page_text = result.stdout.decode('utf-8', errors='ignore').strip()
                        if page_text:
                            text += f"--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1} ---\n{page_text}\n\n"
                            print(f"   ‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ {len(page_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        else:
                            print(f"   ‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")
                    else:
                        print(f"   ‚ùå –û—à–∏–±–∫–∞ Tesseract")

                    try:
                        os.unlink(image_path)
                    except:
                        pass

                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {i+1}: {e}")
                    continue

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR: {e}")
        return text


def extract_text_from_pdf(file_path: str) -> str:
    text = ""
    print(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª: {os.path.basename(file_path)}")
    try:
        print("üîÑ –ü—Ä–æ–±—É—é OCR...")
        ocr_text = OCRProcessor.extract_text_with_ocr(file_path)
        if ocr_text.strip():
            text = ocr_text
            print(f"üëÅÔ∏è OCR: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        else:
            print("‚ùå OCR –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() or ""
                    text += "\n\n"
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
    print(f"‚úÖ –ò—Ç–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
    return text


def parse_diploma_text(text: str) -> Dict[str, Any]:
    """–ü–∞—Ä—Å–∏—Ç –¥–∏–ø–ª–æ–º: —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å, –≥–æ–¥, –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã"""
    result = {
        "specialty": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ",
        "graduation_year": "–ù–µ –Ω–∞–π–¥–µ–Ω",
        "disciplines": []
    }

    # === –ü–û–ò–°–ö –°–ü–ï–¶–ò–ê–õ–¨–ù–û–°–¢–ò ===
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    full_text = " ".join(lines).lower()

    if '38.03.04' in full_text or '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏ –º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ' in full_text:
        result["specialty"] = "38.03.04 –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏ –º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ"
    elif '09.03.03' in full_text or '–ø—Ä–∏–∫–ª–∞–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞' in full_text:
        result["specialty"] = "09.03.03 –ü—Ä–∏–∫–ª–∞–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞"

    # === –ü–û–ò–°–ö –ì–û–î–ê ===
    for line in lines:
        if '–∞—Ç—Ç–µ—Å—Ç–∞—Ç –æ —Å—Ä–µ–¥–Ω–µ–º –æ–±—â–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏' in line.lower() or 'cpeHeM oomeM oopa3OBaHin' in line:
            year_match = re.search(r'(202[0-9])', line)
            if year_match:
                result["graduation_year"] = year_match.group(1)
                break

    # === –ü–û–ò–°–ö –î–ò–°–¶–ò–ü–õ–ò–ù ===
    in_section = False
    for line in lines:
        if not in_section and any(kw in line.lower() for kw in ['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–∞–º—Å–∏—Ü–∏–ø–ª–∏–Ω—ã', 'amci', '–¥–∏—Å—Ü–∏–ø–ª–∏']):
            in_section = True
            continue
        if not in_section:
            continue
        if any(kw in line.lower() for kw in ['–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ', '–ø–æ–¥–ø–∏—Å—å', '–∏—Ç–æ–≥–æ', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ']):
            break

        # –ß–∏—Å—Ç–∏–º —Å—Ç—Ä–æ–∫—É
        clean = re.sub(r'\s*\d+\.?\d*\s*[–µ–∑\.]+\s*', ' ', line)
        clean = re.sub(r'[^\w\s–∞-—è—ë–ê-–Ø–Å\-]', ' ', clean)
        clean = re.sub(r'\s+', ' ', clean).strip()

        # –ü–æ–∏—Å–∫ –æ—Ü–µ–Ω–∫–∏ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
        grade = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        word = clean.upper()

        if any(x in word for x in ['–û–¢–õ–ò–ß–ù–û', '5', 'OTJIM4HO', 'OTIH4HO', 'OTNBO', 'OTI4HO', 'OTJILYHO', 'OTJIEIHHO']):
            grade = "5"
        elif any(x in word for x in ['–•–û–†–û–®–û', '4', 'XOPOMO', 'XOPOO', 'ONCHO', 'ONLHO']):
            grade = "4"
        elif any(x in word for x in ['–£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û', '3', 'YAO', '3a4TeHo', '3a4TCH0', '3aTeHo']):
            grade = "3"
        elif any(x in word for x in ['–ó–ê–ß–¢–ï–ù–û', '–ó–ê–ß–ï–¢', '3A4TEH', '3a4TeHo', '3ayTeHo']):
            grade = "–∑–∞—á—Ç–µ–Ω–æ"
        elif any(x in word for x in ['–ù–ï–£–î', '2']):
            grade = "2"

        if grade != "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
            # –£–¥–∞–ª—è–µ–º –æ—Ü–µ–Ω–∫—É –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            name = re.sub(r'\s+(–æ—Ç–ª–∏—á–Ω–æ|—Ö–æ—Ä–æ—à–æ|—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ|–∑–∞—á—Ç–µ–Ω–æ|–∑–∞—á–µ—Ç|–Ω–µ—É–¥|5|4|3|2|OTJIM4HO|OTIH4HO|3a4TeHo|3a4TCH0|3aTeHo|3a4TCHO|ONCHO|ONLHO).*$', '', clean, flags=re.IGNORECASE)
            name = re.sub(r'\s+', ' ', name).strip()
            if name and len(name) > 3:
                result["disciplines"].append({
                    "name": name,
                    "grade": grade
                })

    return result  # ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: return –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏


def process_diploma(file_path: str, student_name: str = None) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∏–ø–ª–æ–º"""
    print(f"\nüéØ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∏–ø–ª–æ–º: {os.path.basename(file_path)}")
    print("=" * 50)

    if not os.path.exists(file_path):
        return {"error": "–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"}

    file_size = os.path.getsize(file_path)
    print(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
    if file_size == 0:
        return {"error": "–§–∞–π–ª –ø—É—Å—Ç–æ–π"}

    text = extract_text_from_pdf(file_path)
    if not text.strip():
        return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç"}

    parsed = parse_diploma_text(text)
    disciplines_count = len(parsed["disciplines"])

    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    result = {
        "source_file": os.path.basename(file_path),
        "type": "diploma",
        "data": {
            "student_name": student_name or "–ù–µ —É–∫–∞–∑–∞–Ω–æ",
            "specialty": parsed["specialty"],
            "graduation_year": parsed["graduation_year"],
            "disciplines": parsed["disciplines"]
        },
        "disciplines_count": disciplines_count
    }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_dir = "data/parsed_diplomas"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, f"{Path(file_path).stem}_parsed.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=4)

    print("=" * 50)
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"   üë§ –°—Ç—É–¥–µ–Ω—Ç: {result['data']['student_name']}")
    print(f"   üéì –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å: {result['data']['specialty']}")
    print(f"   üìÖ –ì–æ–¥: {result['data']['graduation_year']}")
    print(f"   üìö –î–∏—Å—Ü–∏–ø–ª–∏–Ω: {disciplines_count}")

    return result